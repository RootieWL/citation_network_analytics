{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import DataFrameWriter\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import least\n",
    "from pyspark.sql.functions import greatest\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load author data into dataframe\n",
    "author_file = \"/FileStore/tables/graph/AMiner_Author-81e2b.txt\"\n",
    "\n",
    "def format_data(item=None, replace_term=None, split=False, split_term=\";\"):\n",
    "    tmp = item.replace(replace_term, \"\").strip()\n",
    "    if split:\n",
    "        return tmp.split(split_term) if tmp != \"\" else list()\n",
    "    return tmp\n",
    "  \n",
    "author_rdd = spark.sparkContext \\\n",
    "    .newAPIHadoopFile(path=author_file,\n",
    "                      inputFormatClass=\"org.apache.hadoop.mapreduce.lib.input.TextInputFormat\",\n",
    "                      keyClass=\"org.apache.hadoop.io.LongWritable\",\n",
    "                      valueClass=\"org.apache.hadoop.io.Text\",\n",
    "                      conf={\"textinputformat.record.delimiter\": \"#index \"}) \\\n",
    "    .filter(lambda x: x[1] != \"\") \\\n",
    "    .map(lambda x: (x[0], x[1].split(\"\\n\"))) \\\n",
    "    .flatMap(lambda x: [{\"id\": int(format_data(x[1][0], \"\")),\n",
    "                         \"name\": format_data(x[1][1], \"#n\"),\n",
    "                         \"affiliations\": format_data(x[1][2], \"#a\", True),\n",
    "                         \"published papers\": int(format_data(x[1][3], \"#pc\")),\n",
    "                         \"citations\": int(format_data(x[1][4], \"#cn\")),\n",
    "                         \"h-index\": int(format_data(x[1][5], \"#hi\")),\n",
    "                         \"p-index\": float(format_data(x[1][6], \"#pi\")),\n",
    "                         \"up-index\": float(format_data(x[1][7], \"#upi\")),\n",
    "                         \"keyterms\": format_data(x[1][8], \"#t\", True)}])\n",
    "\n",
    "author = author_rdd.toDF()\n",
    "print(author.count())\n",
    "print(author.distinct().count())\n",
    "author.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paper data into dataframe\n",
    "paper_file = \"/FileStore/tables/graph/AMiner_Paper-478c8.txt\"\n",
    "\n",
    "def format_data(item=None, replace_term=None, split=False, split_term=\";\"):\n",
    "    tmp = item.replace(replace_term, \"\").strip()\n",
    "    if split:\n",
    "        return tmp.split(split_term) if tmp != \"\" else list()\n",
    "    return tmp\n",
    "\n",
    "def format_year(replace_term=None, item=None):\n",
    "    try:\n",
    "        return int(format_data(item, replace_term))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "paper_rdd = spark.sparkContext \\\n",
    "     .newAPIHadoopFile(path=paper_file,\n",
    "                       inputFormatClass=\"org.apache.hadoop.mapreduce.lib.input.TextInputFormat\",\n",
    "                       keyClass=\"org.apache.hadoop.io.LongWritable\",\n",
    "                       valueClass=\"org.apache.hadoop.io.Text\",\n",
    "                       conf={\"textinputformat.record.delimiter\": \"#index \"}) \\\n",
    "     .filter(lambda x: x[1] != \"\") \\\n",
    "     .map(lambda x: (x[0], x[1].split(\"\\n\"))) \\\n",
    "     .flatMap(lambda x: [{\"id\": int(format_data(x[1][0], \"\")),\n",
    "                          \"title\": format_data(x[1][1], \"#*\"),\n",
    "                          \"authors\": format_data(x[1][2], \"#@\", True),\n",
    "                          \"affiliations\": format_data(x[1][3], \"#o\", True),\n",
    "                          \"year\": format_year(\"#t\", x[1][4]),\n",
    "                          \"publication venue\": format_data(x[1][5], \"#c\")}])\n",
    "\n",
    "paper = sqlContext.createDataFrame(paper_rdd)\n",
    "print(paper.count())\n",
    "print(paper.distinct().count())\n",
    "paper.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load author2paper data into dataframe\n",
    "author2papersc = sc.textFile(\"/FileStore/tables/graph/AMiner_Author2Paper-df443.txt\")\n",
    "author2paper = sqlContext.createDataFrame(author2papersc.map(lambda a :tuple(a.split(\"\\t\"))),['index','authorid', 'paperid', 'position'])\n",
    "author2paper = author2paper.withColumn(\"index\", author2paper[\"index\"].cast(IntegerType())).withColumn(\"authorid\", author2paper[\"authorid\"].cast(IntegerType())).withColumn(\"paperid\", author2paper[\"paperid\"].cast(IntegerType())).withColumn(\"position\", author2paper[\"position\"].cast(IntegerType()))\n",
    "print(author2paper.count())\n",
    "print(author2paper.distinct().count())\n",
    "author2paper.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load coauthor data into dataframe\n",
    "coauthorsc = sc.textFile(\"/FileStore/tables/graph/AMiner_Coauthor-2abe4.txt\")\n",
    "coauthor = sqlContext.createDataFrame(coauthorsc.filter(lambda r: r.startswith('#')).map(lambda x: re.sub('#', '', x)).map(lambda a :tuple(a.split(\"\\t\"))),['author1','author2', 'collaborationcount'])\n",
    "coauthor = coauthor.withColumn(\"author1\", coauthor[\"author1\"].cast(IntegerType())).withColumn(\"author2\", coauthor[\"author2\"].cast(IntegerType())).withColumn(\"collaborationcount\", coauthor[\"collaborationcount\"].cast(IntegerType()))\n",
    "print(coauthor.count())\n",
    "print(coauthor.distinct().count())\n",
    "coauthor.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get publish year for author2paper dataframe\n",
    "authorpaper = author2paper.join(paper[['id', 'year']], author2paper.paperid == paper[['id', 'year']].id, 'inner').drop(paper[['id', 'year']].id)\n",
    "print(authorpaper.count())\n",
    "print(authorpaper.distinct().count())\n",
    "authorpaper.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first year of collaboration between two authors\n",
    "authorpaper1 = authorpaper[['authorid', 'paperid', 'year']].withColumnRenamed('authorid', 'authorid1').withColumnRenamed('paperid', 'paperid1')\n",
    "coauthor = coauthor.join(authorpaper1, coauthor.author1 == authorpaper1.authorid1, 'inner').drop(authorpaper1.authorid1)\n",
    "print(coauthor.count())\n",
    "print(coauthor.distinct().count())\n",
    "coauthor.show(5)\n",
    "\n",
    "authorpaper2 = authorpaper[['authorid', 'paperid']].withColumnRenamed('authorid', 'authorid2').withColumnRenamed('paperid', 'paperid2')\n",
    "coauthor = coauthor.join(authorpaper2, (coauthor.author2 == authorpaper2.authorid2) & (coauthor.paperid1 == authorpaper2.paperid2), 'inner').drop(authorpaper2.authorid2)\n",
    "print(coauthor.count())\n",
    "print(coauthor.distinct().count())\n",
    "coauthor.show(5)\n",
    "\n",
    "w = Window.partitionBy('author1', 'author2')\n",
    "coauthor_final = coauthor.withColumn('1styear', f.min('year').over(w))\\\n",
    "                  .where(f.col('year') == f.col('1styear'))\\\n",
    "                  .drop('1styear')\n",
    "\n",
    "coauthor_final = coauthor_final[['author1', 'author2', 'year']].distinct()\n",
    "print(coauthor_final.count())\n",
    "print(coauthor_final.distinct().count())\n",
    "coauthor_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy('author1', 'author2')\n",
    "coauthor_final = coauthor.withColumn('1styear', f.min('year').over(w))\\\n",
    "                  .where(f.col('year') == f.col('1styear'))\\\n",
    "                  .drop('1styear')\n",
    "\n",
    "coauthor_final = coauthor_final[['author1', 'author2', 'year']].distinct()\n",
    "print(coauthor_final.count())\n",
    "print(coauthor_final.distinct().count())\n",
    "coauthor_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(coauthor_final.groupBy(\"year\").agg(count(lit(1)).alias(\"count\")).orderBy(\"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_writer_coauthor_final = DataFrameWriter(coauthor_final)\n",
    "df_writer_coauthor_final.saveAsTable(\"coauthor_final\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_final = spark.sql(\"select * from coauthor_final\")\n",
    "coauthor_late = coauthor_final.where(col('year') >= 2010)\n",
    "coauthor_early = coauthor_final.where((col('year') < 2010))\n",
    "print(coauthor_early.count(), coauthor_late.count())\n",
    "df_writer_coauthor_late = DataFrameWriter(coauthor_late)\n",
    "df_writer_coauthor_early = DataFrameWriter(coauthor_early)\n",
    "\n",
    "df_writer_coauthor_late.saveAsTable(\"late\", mode=\"overwrite\")\n",
    "df_writer_coauthor_early.saveAsTable(\"early\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coauthor_early = spark.sql(\"select * from early\")\n",
    "coauthor_late = spark.sql(\"select * from late\")\n",
    "\n",
    "author_list_early = coauthor_early[['author1']].union(coauthor_early[['author2']]).distinct().withColumnRenamed('author1', 'id')\n",
    "author_list_late = coauthor_late[['author1']].union(coauthor_late[['author2']]).distinct().withColumnRenamed('author1', 'id')\n",
    "coauthor_early_final = coauthor_early.withColumn('src', least('author1', 'author2')).withColumn('dst', greatest('author1', 'author2'))[['src', 'dst']]\n",
    "coauthor_late_final = coauthor_late.withColumn('src', least('author1', 'author2')).withColumn('dst', greatest('author1', 'author2'))[['src', 'dst']]\n",
    "author_list_final = author_list_early.join(author_list_late, author_list_early.id == author_list_late.id, 'inner').drop(author_list_late.id)\n",
    "\n",
    "df_writer_edges = DataFrameWriter(coauthor_early_final)\n",
    "df_writer_vertices = DataFrameWriter(author_list_early)\n",
    "\n",
    "df_writer_edges.saveAsTable(\"edges\", mode=\"overwrite\")\n",
    "df_writer_vertices.saveAsTable(\"vertices\", mode=\"overwrite\")\n",
    "\n",
    "df_writer_coauthor_late_final = DataFrameWriter(coauthor_late_final)\n",
    "df_writer_author_list_final = DataFrameWriter(author_list_final)\n",
    "\n",
    "df_writer_coauthor_late_final.saveAsTable(\"late_final\", mode=\"overwrite\")\n",
    "df_writer_author_list_final.saveAsTable(\"list_final\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[15]: 175065</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql('select * from list_final').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coauthor_late_final = spark.sql(\"select * from late_final\")\n",
    "author_list_final = spark.sql(\"select * from list_final\")\n",
    "edges = spark.sql(\"select * from edges\")\n",
    "coauthor_late_final = coauthor_late_final.withColumn('target', lit(1))\n",
    "left = author_list_final.withColumnRenamed('id', 'author1')\n",
    "right = author_list_final.withColumnRenamed('id', 'author2')\n",
    "data = left.join(right, left.author1 < right.author2, 'cross')\n",
    "data = data.join(edges, (data.author1 == edges.src) & (data.author2 == edges.dst), 'left_anti')\n",
    "data = data.join(coauthor_late_final, (data.author1 == coauthor_late_final.src) & (data.author2 == coauthor_late_final.dst), 'left').drop(coauthor_late_final.src).drop(coauthor_late_final.dst)\n",
    "data = data.fillna({'target':0})\n",
    "df_writer_data = DataFrameWriter(data)\n",
    "df_writer_data.saveAsTable(\"data\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+------+-----------+\n",
       "target|      count|\n",
       "+------+-----------+\n",
       "     1|     259213|\n",
       "     0|15323003997|\n",
       "+------+-----------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = spark.sql(\"select * from data\")\n",
    "data.groupBy(\"target\").agg(count(lit(1)).alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample train and test data. Train data is balanced by undersampling. Test data is supposed to use original dataset but due to computational expensiveness it is also undersampled\n",
    "trainsplit, testsplit = data.randomSplit([0.8, 0.2], seed=123)\n",
    "train_pos = trainsplit.filter(f.col('target') == 1)\n",
    "train_neg = trainsplit.filter(f.col('target') == 0).sample(False, 0.000017, seed=1)\n",
    "train = train_pos.union(train_neg)\n",
    "train = train.withColumn('train', lit(1))\n",
    "\n",
    "test_pos = testsplit.filter(f.col('target') == 1)\n",
    "test_neg = testsplit.filter(f.col('target') == 0).sample(False, 0.000017, seed=2)\n",
    "test = test_pos.union(test_neg)\n",
    "test = test.withColumn('train', lit(0))\n",
    "\n",
    "train_data = train.union(test)\n",
    "df_writer_train = DataFrameWriter(train_data)\n",
    "df_writer_train.saveAsTable(\"train_data\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n",
       "import org.apache.spark.rdd.RDD.numericRDDToDoubleRDDFunctions\n",
       "import ml.sparkling.graph.operators.OperatorsDSL._\n",
       "import ml.sparkling.graph.operators.measures.edge.AdamicAdar\n",
       "import ml.sparkling.graph.operators.measures.edge.CommonNeighbours\n",
       "import org.apache.spark.graphx.Graph\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.DataFrame\n",
       "import java.lang.Long\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "// Calculate Common Neighbors, Total Neighbors, Preferential Attachment, Jaccard Similarity, Adamic Adar and Resource Allocation\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.rdd.RDD.numericRDDToDoubleRDDFunctions\n",
    "import ml.sparkling.graph.operators.OperatorsDSL._\n",
    "import ml.sparkling.graph.operators.measures.edge.AdamicAdar\n",
    "import ml.sparkling.graph.operators.measures.edge.CommonNeighbours\n",
    "import org.apache.spark.graphx.Graph\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import java.lang.Long;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">PreprocessedRDD: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[6732] at map at command-2170733821474522:1\n",
       "Node1Vertex: org.apache.spark.rdd.RDD[(Long, Int)] = MapPartitionsRDD[6736] at distinct at command-2170733821474522:2\n",
       "Node2Vertex: org.apache.spark.rdd.RDD[(Long, Int)] = MapPartitionsRDD[6740] at distinct at command-2170733821474522:3\n",
       "completeVertex: org.apache.spark.rdd.RDD[(Long, Int)] = MapPartitionsRDD[6744] at distinct at command-2170733821474522:4\n",
       "EdgesRDD: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Int]] = MapPartitionsRDD[6748] at distinct at command-2170733821474522:5\n",
       "graph: org.apache.spark.graphx.Graph[Int,Int] = org.apache.spark.graphx.impl.GraphImpl@7b6aaaf0\n",
       "neigh: org.apache.spark.graphx.VertexRDD[Array[org.apache.spark.graphx.VertexId]] = VertexRDDImpl[6766] at RDD at VertexRDD.scala:57\n",
       "broadcastVar: org.apache.spark.broadcast.Broadcast[Array[(org.apache.spark.graphx.VertexId, Array[org.apache.spark.graphx.VertexId])]] = Broadcast(3720)\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val PreprocessedRDD = spark.sql(\"select * from edges\").rdd.map{_.toSeq.map{_.toString}.toArray}.cache()\n",
    "val Node1Vertex = PreprocessedRDD.map(line=>(line(0).toLong,1)).distinct()\n",
    "val Node2Vertex = PreprocessedRDD.map(line=>(line(1).toLong,1)).distinct()\n",
    "val completeVertex = Node1Vertex.union(Node2Vertex).distinct\n",
    "val EdgesRDD = PreprocessedRDD.map(line=>(Edge(line(0).toLong,line(1).toLong,1))).distinct()\n",
    "\n",
    "val graph=Graph(completeVertex,EdgesRDD).persist().cache();\n",
    "val neigh =graph.collectNeighborIds(EdgeDirection.Either)\n",
    "val broadcastVar = sc.broadcast(neigh.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">PreprocessedRDDLabelRaw: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[6771] at map at command-2170733821474523:1\n",
       "labelDataToRdd: org.apache.spark.broadcast.Broadcast[Array[Array[String]]] = Broadcast(3724)\n",
       "Degree: Array[(org.apache.spark.graphx.VertexId, Int)] = Array((228384,1), (152288,3), (364608,5), (1340736,27), (1586656,2), (984224,7), (23776,4), (1635872,2), (790880,13), (1297504,15), (507904,8), (1397952,2), (997728,2), (1052416,13), (1662176,5), (579456,3), (1522272,5), (559456,5), (1469920,1), (405792,26), (784768,3), (990464,6), (1394592,4), (1119712,1), (4992,2), (1269728,7), (1135328,3), (267968,4), (443680,6), (356800,1), (1285280,1), (143584,2), (642848,4), (1542080,7), (311424,4), (1354912,15), (658016,3), (1182656,1), (368032,1), (1384032,2), (1546336,6), (694912,2), (1135904,5), (1087488,15), (946144,2), (182336,1), (341152,4), (482048,48), (464160,5), (1232736,23), (1098016,3), (1673696,4), (278400,2), (1076512,2), (1293920,2), (306976,33), (758080,2), (1094976,5), (1296256,1), (834816,2), (11904,2), (1594400,1), (388544,18), (1431616,12), (1442720,2), (1034464,5), (447488,1), (1584512,1), (1638016,5), (932544,4), (1488832,1), (360192,6), (499936,1), (1291712,5), (1295168,4), (967360,2), (1252640,12), (1386368,1), (1441152,6), (124224,7), (1198912,1), (1415040,1), (1277472,4), (853024,2), (901152,1), (1628032,1), (1575744,2), (292864,5), (475424,14), (1434336,13), (331968,5), (1105920,2), (1188352,2), (836128,2), (1600704,1), (1139776,4), (917632,1), (1679840,4), (1563392,8), (1660640,7), (838688,3), (1563840,2), (930368,12), (1418880,5), (366528,1), (515488,3), (334880,2), (549024,1), (1009920,1), (1026944,1), (1418208,4), (289184,3), (1550624,2), (899328,7), (999616,2), (750720,3), (1216640,1), (108160,4), (529088,10), (126752,2), (833664,2), (907360,1), (712192,6), (1709952,1), (468768,3), (1405504,1), (548768,20), (1154592,4), (130272,13), (1666688,5), (1437248,8), (1558304,5), (1319264,1), (1118048,5), (649216,5), (372096,9), (1453920,1), (936512,2), (1251040,2), (964256,3), (1220480,5), (1644608,7), (1283968,8), (860224,4), (1079072,2), (1466880,1), (743136,1), (911584,2), (990208,1), (195040,5), (477984,4), (1381344,11), (777312,3), (1416096,8), (1189376,3), (418624,1), (1699360,13), (105856,4), (66816,2), (43456,3), (36512,1), (56544,3), (636928,7), (222016,3), (615584,2), (1077440,13), (669312,4), (197408,2), (175008,5), (638496,7), (351680,1), (1502112,1), (776832,2), (1210944,17), (891520,4), (422784,5), (1327680,1), (1220416,7), (1039904,12), (72864,1), (1602656,4), (129280,4), (354688,3), (266208,3), (1707552,3), (175744,2), (255808,2), (1686272,9), (1290048,4), (931520,11), (1167424,1), (993344,4), (1063808,1), (646176,7), (1634688,3), (612800,3), (1342784,1), (330688,1), (292160,1), (1427936,1), (354752,9), (177056,3), (83360,8), (1327168,2), (443936,5), (315968,6), (784704,3), (302688,6), (609440,8), (1463648,3), (1071936,3), (141984,3), (545824,4), (1031584,13), (118240,4), (8896,4), (1520000,10), (1243520,2), (1211200,2), (118208,13), (375456,7), (1442528,9), (370048,4), (1341344,3), (250080,31), (202048,2), (1125120,3), (1053760,10), (870624,5), (930496,13), (1692160,2), (562304,3), (250048,2), (1315776,1), (115104,1), (1585696,3), (119264,3), (1610944,4), (579136,2), (517152,1), (580896,4), (355360,3), (904352,11), (720928,8), (1480704,2), (231872,2), (718464,14), (1642720,2), (527008,2), (13216,6), (71872,4), (1012896,2), (1070400,4), (1145696,3), (1586112,1), (1629088,41), (306112,7), (1356416,18), (504576,1), (850528,3), (836896,2), (975392,3), (718656,3), (1604768,1), (827648,2), (915456,2), (1631168,3), (82912,2), (1462944,14), (732384,8), (1674688,3), (1387552,1), (961056,1), (1495424,3), (139040,4), (81376,5), (95008,1), (1098944,1), (1576928,4), (1325568,5), (1136416,16), (517824,12), (1693440,3), (892704,2), (960512,4), (1003456,20), (213472,1), (1398432,1), (1056096,6), (1302368,3), (1538752,4), (320000,7), (1002784,1), (784320,7), (397056,8), (235968,3), (382016,2), (927264,2), (736576,4), (746880,4), (837984,3), (366368,2), (865216,8), (649600,2), (850304,1), (1096128,3), (421120,16), (1571584,4), (732352,2), (415456,2), (516544,4), (235648,2), (1114016,6), (470080,1), (1262656,4), (1146400,1), (1322656,3), (3360,24), (579008,4), (465344,1), (31936,10), (550784,3), (13696,41), (762144,25), (1485984,30), (1476000,3), (1542624,3), (800448,15), (1158400,2), (1645600,10), (1565568,3), (548000,4), (98080,1), (1192448,2), (424512,8), (524800,9), (853408,4), (1445664,2), (721600,1), (183200,3), (216256,2), (731936,2), (114560,4), (441056,4), (1440352,11), (302368,1), (193632,2), (135744,4), (27200,1), (801824,3), (1452864,6), (30912,2), (1334272,2), (911328,3), (384416,7), (1091424,2), (1358112,2), (1556416,5), (443392,1), (397408,4), (170912,7), (879584,3), (1711360,2), (164480,5), (443040,5), (653856,2), (712256,6), (349632,1), (1253472,6), (1047808,1), (159936,4), (1246464,3), (1373056,6), (1708128,3), (469664,1), (780320,4), (1184000,4), (478208,3), (690048,1), (137760,2), (259040,1), (1225216,5), (1565152,5), (154240,5), (1070528,4), (1240416,2), (1456256,1), (955872,1), (904288,2), (108992,3), (1119968,4), (483136,2), (1344960,1), (1483072,3), (870368,2), (1179936,8), (1423104,2), (1565472,1), (56512,9), (48640,2), (446624,3), (1608768,1), (89920,2), (76800,1), (545984,1), (1527680,1), (906880,3), (110464,4), (1576384,2), (791840,8), (1439936,2), (703744,1), (572672,6), (1268224,5), (1340000,4), (491392,2), (690304,2), (205792,12), (572096,1), (1054976,2), (424288,1), (785344,2), (1020256,2), (218272,1), (461152,10), (217824,4), (246464,5), (443136,2), (204512,8), (198336,2), (1018464,1), (1706848,4), (747744,4), (532512,1), (1031776,1), (1211040,4), (947424,1), (875744,11), (505152,2), (1619360,3), (284096,5), (1185600,2), (1174592,3), (822176,3), (150336,3), (10240,2), (1659328,4), (1217152,7), (388832,3), (1038080,3), (447008,1), (184224,3), (406688,3), (1261984,1), (1518560,2), (1159456,2), (1090784,10), (938240,1), (255904,1), (552608,1), (1068448,4), (1190912,4), (1560608,1), (402112,1), (865920,10), (647328,1), (576096,6), (1255520,1), (994112,5), (310912,23), (416608,1), (457856,3), (658304,1), (123680,5), (1656544,4), (317728,2), (1411392,5), (665120,3), (1342976,4), (621376,2), (1211360,1), (107232,7), (51840,52), (1366016,4), (1531104,4), (1270080,2), (317632,3), (885088,2), (50368,1), (1659168,4), (76768,1), (549056,5), (1333600,2), (209120,1), (663968,3), (1700192,1), (822080,1), (35936,12), (1184416,4), (1168832,3), (1457984,25), (1123136,2), (1633280,1), (127040,5), (11264,12), (1244096,12), (1404960,4), (997280,2), (734272,4), (1243680,2), (921248,1), (1294656,4), (482752,7), (665184,4), (1610720,2), (79712,3), (470912,3), (1135008,9), (692160,16), (376832,1), (1568640,1), (202656,7), (493088,1), (1405056,1), (1554176,2), (786080,1), (1029184,7), (850848,3), (1619232,1), (1555840,3), (972544,5), (1361472,44), (849600,14), (96800,4), (107872,4), (1267360,3), (1500384,17), (1620832,3), (64896,4), (1609184,2), (587008,2), (1372224,2), (598048,1), (1036480,1), (372416,1), (668000,3), (150784,2), (1492992,6), (470176,28), (207456,8), (1588928,3), (1625024,1), (1041920,3), (242048,3), (1597504,3), (483552,2), (320352,13), (1005728,2), (1475456,2), (592768,8), (1202624,2), (1282752,2), (821344,3), (1466720,2), (1242464,3), (1239744,5), (733056,1), (635488,3), (1443136,7), (683776,2), (1463424,7), (494304,5), (1284832,2), (1001600,3), (691808,4), (392864,1), (475328,5), (512736,3), (1083424,2), (345344,1), (1363360,5), (1594528,6), (61440,1), (1416160,3), (125056,2), (1607008,2), (772960,4), (240512,5), (969312,1), (524672,5), (283424,3), (181248,1), (1668512,50), (77792,1), (942528,9), (555392,5), (864864,201), (793440,1), (917984,1), (490176,15), (1201568,3), (729568,3), (287008,2), (1510848,2), (1328736,7), (1319360,10), (1612416,1), (1334656,1), (1331872,3), (114336,7), (137568,3), (1632160,4), (951840,1), (1196832,1), (874112,2), (533280,1), (1314624,9), (769760,1), (1652928,3), (467680,4), (840608,2), (130976,1), (1327648,3), (757696,4), (1363520,33), (1551936,2), (1126112,1), (317600,31), (1598144,5), (1537696,16), (536512,2), (1027296,2), (1292096,4), (944832,2), (391968,28), (1705120,5), (1178336,4), (1337120,1), (928448,8), (583232,2), (1321600,1), (617120,11), (944096,5), (609792,3), (1506464,1), (1374336,4), (1203744,2), (827456,14), (161088,6), (636544,3), (657248,7), (564512,1), (869440,6), (552640,2), (1267776,3), (1416544,10), (1384992,2), (13344,5), (1155552,1), (1055232,1), (561152,4), (1074560,2), (809824,1), (750304,3), (765600,3), (436448,1), (1565024,2), (529408,3), (58752,3), (881248,3), (1562976,2), (1392224,7), (268352,1), (178208,9), (608,7), (1625856,4), (1003296,5), (391776,7), (874208,4), (1344896,2), (1263936,3), (290464,3), (1013088,4), (484096,3), (649088,2), (192032,3), (1370720,3), (645728,3), (822336,2), (729728,5), (979072,2), (47968,3), (550656,3), (1590304,1), (1307168,1), (265600,7), (523776,2), (377984,4), (130176,5), (1640512,2), (431200,1), (1656512,6), (1421216,2), (1406336,9), (1483328,3), (1419360,3), (351968,2), (1124608,2), (838464,2), (522752,21), (1427904,8), (1309024,7), (709280,14), (463136,2), (528992,1), (1295808,3), (1710048,2), (889568,1), (1160032,5), (1086752,10), (25344,1), (1510688,5), (869568,3), (1129792,2), (1362048,6), (928032,1), (1404032,3), (209184,5), (804960,4), (82656,4), (1602624,3), (1416576,1), (798016,2), (1282496,5), (865024,1), (66560,6), (1436832,4), (926176,12), (712608,2), (666496,9), (733600,2), (1377248,3), (293696,2), (167424,1), (240992,5), (827552,16), (842816,10), (237952,2), (446464,38), (467104,5), (934816,1), (788352,1), (1467008,3), (1056672,2), (522496,6), (1621920,3), (43072,1), (308480,4), (733536,1), (408960,7), (1187936,2), (1397312,4), (1635520,3), (1109184,1), (101696,25), (1326560,3), (34560,2), (1615840,4), (888640,1), (730240,2), (1444576,4), (460608,1), (478880,9), (237184,3), (1111360,4), (348352,1), (733984,1), (508224,2), (1138592,1), (1182176,6), (1074752,2), (434720,2), (1510400,2), (1678368,6), (264128,4), (661120,3), (909600,2), (134272,3), (673056,5), (1693504,2), (7904,6), (2144,2), (1286720,7), (204704,19), (894432,4), (1506592,2), (1020416,1), (1430560,3), (506656,7), (548064,6), (1200160,2), (1278176,1), (116960,1), (447552,6), (671488,3), (948736,1), (1226016,1), (317088,17), (520704,3), (384672,3), (1245120,3), (358624,3), (1202080,2), (1021664,4), (489440,1), (695840,1), (1381472,1), (557408,8), (494176,14), (71552,6), (1222400,2), (527456,10), (1068960,1), (418016,2), (920768,2), (716768,3), (1454336,27), (137088,8), (884896,10), (592512,1), (60960,14), (445664,1), (35424,2), (1075168,1), (1512032,4), (89248,2), (64128,5), (857088,4), (769856,3), (1326592,3), (676704,3), (303296,8), (244032,7), (23840,2), (116576,4), (676896,3), (586496,3), (311552,2), (1342560,5), (950496,17), (1416320,2), (52000,3), (593344,17), (1448640,2), (648288,6), (88352,2), (1596000,2), (489184,3), (1541536,1), (1361024,16), (1459808,25), (1437984,6), (741824,4), (1357504,13), (112928,2), (852736,2), (1351232,1), (1464832,3), (695264,1), (991392,1), (668640,1), (575328,5), (877088,19), (120800,1), (950656,6), (996896,3), (28160,1), (636256,2), (234528,5), (1660704,6), (780576,6), (352960,2), (380544,1), (614240,15), (1196512,7), (1411136,3), (87168,1), (1461216,4), (648672,2), (714720,1), (506016,7), (106496,3), (1457024,3), (1439520,4), (720640,8), (485408,2), (1004256,2), (1033984,49), (1385504,4), (1682080,3), (371872,7), (194176,5), (692992,7), (1361504,4), (1060704,13), (267008,30), (762944,3), (9152,12), (1310304,9), (91008,4), (117696,5), (870752,9), (1659104,6), (1155232,10), (998752,15), (301984,1), (399136,3), (837024,2), (1666432,1), (149824,7), (528480,2), (22752,4), (228896,3), (1615520,12), (1559744,4), (1254816,12), (626528,5), (176000,15), (776192,4), (1403392,5), (400736,33), (497984,4), (1058016,9), (1546720,5), (762976,1), (1578208,1), (1202784,1), (1326784,4), (1537600,2), (139360,4), (264704,2), (791936,8), (133312,1), (951744,1), (1012288,2), (911680,2), (1701696,4), (1529440,1), (1009472,5), (233792,4), (354720,2), (398976,2), (1636576,6), (219744,4), (820768,4), (841472,3), (852864,2), (722080,5), (1321248,8), (218048,3), (1470528,3), (1678016,2), (1514784,4), (1711744,3), (324864,1), (845760,12), (1304160,1), (849920,3), (399840,12), (137632,13), (1373376,16), (1509344,4), (496960,4), (785504,1), (808800,3), (1547968,3), (1155680,2), (1058144,2), (1660512,1), (550816,2), (793792,7), (1262720,3), (832576,28), (1124704,3), (190560,1), (1258400,3), (1427328,9), (772352,1), (1020320,1), (629248,1), (458848,5), (815072,2), (621760,4), (1499232,2), (484032,5), (1035232,4), (1446624,3), (1034624,2), (265248,4), (1091648,2))\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val PreprocessedRDDLabelRaw = spark.sql(\"select * from train_data\").rdd.map{_.toSeq.map{_.toString}.toArray}.cache()\n",
    "val labelDataToRdd = sc.broadcast(PreprocessedRDDLabelRaw.collect())\n",
    "val Degree = graph.degrees.collect().toArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">import sqlContext.implicits._\n",
       "import scala.math.sqrt\n",
       "import scala.math.min\n",
       "import scala.math.max\n",
       "r_rdd: org.apache.spark.rdd.RDD[(Long, Long, Int, Int, Int, Double, Double, Double, Double, Double, Double, Double, Double)] = MapPartitionsRDD[73981] at mapPartitions at command-2170733821474524:5\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "import sqlContext.implicits._\n",
    "import scala.math.sqrt\n",
    "import scala.math.min\n",
    "import scala.math.max\n",
    "val r_rdd = PreprocessedRDDLabelRaw.mapPartitions(rows => {\n",
    "      \tval nvalues = broadcastVar.value.toMap\n",
    "      \trows.map(row=>{\n",
    "                val n1 = row(0).toLong            \n",
    "                val n2 = row(1).toLong\n",
    "                val n1_neigh =nvalues(n1)\n",
    "                val n2_neigh =nvalues(n2)  \n",
    "                val common = n1_neigh.intersect(n2_neigh)\n",
    "                val total = n1_neigh.union(n2_neigh).distinct\n",
    "                // Common Neigbors\n",
    "                val common_neighbors = common.length\n",
    "                // Total Neigbors\n",
    "                val total_neighbors = total.length\n",
    "                // Preferential Attachment\n",
    "                val preferential_attachment = n1_neigh.length * n2_neigh.length\n",
    "                // Jacardd Similarity\n",
    "                val jaccard = common.length/total.length.toDouble\n",
    "                // Adamic Adar\n",
    "                val adamic_adar = Degree.filter{case (id, deg) => common.contains(id)}.map(x => 1/math.log(x._2)).sum\n",
    "                // Resource Allocation\n",
    "                val resource_allocation = Degree.filter{case (id, deg) => common.contains(id)}.map(x => 1/x._2.toDouble).sum\n",
    "                // Leicht-Holme-Nerman\n",
    "                val leicht_holme_nerman = (common.length/(n1_neigh.length * n2_neigh.length)).toDouble\n",
    "                // Sorensen Index\n",
    "                val sorensen_index = (common.length/(n1_neigh.length + n2_neigh.length)).toDouble\n",
    "                // Salton Cosine Similarity\n",
    "                val salton_cosine_similarity = common.length/sqrt(n1_neigh.length * n2_neigh.length)\n",
    "                // Hub Promoted\n",
    "                val hub_promoted = (common.length/min(n1_neigh.length, n2_neigh.length)).toDouble\n",
    "                // Hub Depressed\n",
    "                val hub_depressed = (common.length/max(n1_neigh.length, n2_neigh.length)).toDouble\n",
    "                (n1, n2, common_neighbors, total_neighbors, preferential_attachment, jaccard, adamic_adar, resource_allocation, leicht_holme_nerman, sorensen_index, salton_cosine_similarity, hub_promoted, hub_depressed)\n",
    "              })\n",
    "    \t}).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">colNames: Seq[String] = List(author1, author2, common_neighbors, total_neighbors, preferential_attachment, jaccard, adamic_adar, resource_allocation, leicht_holme_nerman, sorensen_index, salton_cosine_similarity, hub_promoted, hub_depressed)\n",
       "neighbor: org.apache.spark.sql.DataFrame = [author1: bigint, author2: bigint ... 11 more fields]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val colNames = Seq(\"author1\", \"author2\", \"common_neighbors\", \"total_neighbors\", \"preferential_attachment\", \"jaccard\", \"adamic_adar\", \"resource_allocation\", \"leicht_holme_nerman\", \"sorensen_index\", \"salton_cosine_similarity\", \"hub_promoted\", \"hub_depressed\")\n",
    "val neighbor = r_rdd.toDF(colNames: _*)\n",
    "neighbor.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"neighbor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community Detection\n",
    "from graphframes import *\n",
    "\n",
    "graph_edges =  spark.sql('select * from edges').select(\"src\", \"dst\")\n",
    "graph_vertices =  spark.sql('select * from vertices')\n",
    "\n",
    "g = GraphFrame(graph_vertices, graph_edges)\n",
    "\n",
    "sc.setCheckpointDir('/FileStore/tables/graph')\n",
    "tc = g.triangleCount()\n",
    "lp = g.labelPropagation(maxIter=2)\n",
    "cc = g.connectedComponents()\n",
    "\n",
    "community = cc.join(tc, cc.id == tc.id).drop(tc.id) \n",
    "community_final = community.join(lp, community.id == lp.id).drop(lp.id).withColumnRenamed('count', 'triangle_count').withColumnRenamed('label', 'label_propagation_cluster_no').withColumnRenamed('component', 'connected_component_cluster_no')\n",
    "df_writer_community = DataFrameWriter(community_final)\n",
    "df_writer_community.saveAsTable(\"community\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('select * from edges').coalesce(1).write.format('json').mode(\"overwrite\").save(\"dbfs:/FileStore/tables/graph/edges\")\n",
    "spark.sql('select * from vertices').coalesce(1).write.format('json').mode(\"overwrite\").save(\"dbfs:/FileStore/tables/graph/vertices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import community \n",
    "import json\n",
    "from networkx.algorithms import community\n",
    "from networkx.algorithms.community import label_propagation_communities\n",
    "from community import community_louvain\n",
    "from random import sample \n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "numpy.random.seed(seed=123)\n",
    "\n",
    "'''\n",
    "Load edges/vertices to networkx and run louvain modularity\n",
    "'''\n",
    "table_graph_edges = '/dbfs/FileStore/tables/graph/edges/part-00000-tid-396298111213125007-c7da24a8-57cb-409d-89e9-3b9e58b9144b-4392457-1-c000.json'\n",
    "table_graph_vertices = '/dbfs/FileStore/tables/graph/vertices/part-00000-tid-1328123797423764871-ba292581-975f-43d9-a96e-bbe7761efc9d-4392458-1-c000.json'\n",
    "\n",
    "edge_list = []\n",
    "for line in open(table_graph_edges, 'r'):\n",
    "    edge_list.append(json.loads(line))\n",
    "    \n",
    "edges_list = [(dic['src'],dic['dst']) for dic in edge_list]\n",
    "\n",
    "vertice_list = []\n",
    "for line in open(table_graph_vertices, 'r'):\n",
    "    vertice_list.append(json.loads(line))\n",
    "    \n",
    "vertice_list = [(dic['id']) for dic in vertice_list]\n",
    "\n",
    "g = nx.Graph()\n",
    "g.add_edges_from(edges_list)\n",
    "g.add_nodes_from(vertice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partition = community_louvain.best_partition(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrameWriter\n",
    "louvain = sqlContext.createDataFrame(pd.DataFrame(list(partition.items()),columns=['id','lv_cluster_no']))\n",
    "df_writer_louvain = DataFrameWriter(louvain)\n",
    "df_writer_louvain.saveAsTable(\"community_louvain\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "community = spark.sql('select * from community')\n",
    "community_louvain = spark.sql('select * from community_louvain')\n",
    "community = community.join(community_louvain, community.id == community_louvain.id).drop(community_louvain.id)\n",
    "community.coalesce(1).write.format('csv').mode(\"overwrite\").save(\"dbfs:/FileStore/tables/graph/community\", header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql('select * from neighbor').coalesce(1).write.format('csv').mode(\"overwrite\").save(\"dbfs:/FileStore/tables/graph/neighbor\", header = 'true')\n",
    "spark.sql('select * from train_data').coalesce(1).write.format('csv').mode(\"overwrite\").save(\"dbfs:/FileStore/tables/graph/train\", header = 'true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Final - 1",
  "notebookId": 2170733821474489
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
